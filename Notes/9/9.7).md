# Docker Compose

## Recap of Containerisation Technologies

*   Progression: Bare Metal -> Virtual Machines -> Docker Containers -> Docker Compose.  Each step builds upon the previous one, adding layers of abstraction and management.

## Motivation for Docker Compose

*   **Problem:** When developing systems with *multiple* containers (e.g., a web application, a database, a message queue), you need to:
    *   Create each container individually (often with its own `Dockerfile`).
    *   Configure networking between them (so they can communicate).
    *   Manage their startup and shutdown order.
    *   Scale individual components.
*   Doing this manually with `docker run` commands is tedious, error-prone, and hard to maintain, especially for complex applications.
*   **Solution:** Docker Compose provides a way to define and manage multi-container applications as a *single unit*.

## Definition of Docker Compose

*   **Tool for defining and running multi-container Docker applications.**  Think of it as a "recipe" for your entire application stack.
*   Uses a **YAML file (typically named `docker-compose.yml`)** to configure all the application's *services*.
*   A *service* in Docker Compose represents a container that will be part of your application.
*   With a **single command (`docker-compose up`)**, you can create and start *all* the services defined in the configuration file.  This greatly simplifies development and deployment.

## Why Use Docker Compose?

*   **Simplifies multi-container application management:** All containers are defined and managed in a single, easy-to-read YAML file.  You don't need to remember complex `docker run` commands for each container.
*   **Ensures consistent environments:** The YAML file allows you to define configurations for all containers, including:
    *   Docker images to use.
    *   Environment variables.
    *   Port mappings (host port to container port).
    *   Volume mounts (for persistent data).
    *   Dependencies between services (e.g., start the database *before* the web application).
    * This ensures a consistent runtime environment regardless of where you run the application (your development machine, a testing server, or production).
*   **Facilitates collaboration:** The `docker-compose.yml` file can be easily shared with other developers, ensuring everyone works with the *same* application environment.  This eliminates "works on my machine" problems.
*   **Makes scaling easier:** You can define the number of replicas for each service in the Compose file, making it simple to scale applications up or down *without* manually managing individual containers.
* **Orchestration:** Compose can handle dependencies.

## Introduction to YML and Compose File Structure

*   Docker Compose uses YAML files (`.yml` or `.yaml` extension) to define the application's services, networks, and volumes.  YAML is a human-readable data serialization format.
*   The main sections within a `docker-compose.yml` file include:

    *   **`version`:**  Specifies the version of the Compose file format.  Different versions support different features.  It's good practice to use a relatively recent version (e.g., "3.9").

    *   **`services`:**  This is the *most important* section.  It defines the individual **containers** that make up your application.
        *   Each service is given a unique name (e.g., `web`, `db`, `redis`).
        *   Under each service name, you configure various options:
            *   `build`:  Specifies how to build the Docker image for this service.  You can:
                *   Use a `Dockerfile` in the current directory (`build: .`).
                *   Specify a path to a different directory containing the `Dockerfile` (`build: ./path/to/dockerfile`).
                *   Provide detailed build context and arguments.
            *   `image`:  Specifies a pre-built image to use (e.g., from Docker Hub).  You can use this *instead of* `build`.
            *   `ports`:  Maps ports between the host and the container (e.g., `"8000:5000"` maps host port 8000 to container port 5000).
            *   `volumes`:  Mounts volumes for persistent data storage.
            *   `environment`:  Sets environment variables inside the container.
            *   `depends_on`:  Specifies dependencies between services.  Compose will start services in the correct order based on these dependencies.
            *   `networks`:  Specifies which networks the service should connect to.

    *   **`volumes`:**  (Optional) This section defines *named volumes* that can be used for persistent data storage and shared between containers.  Named volumes are managed by Docker and are more flexible than bind mounts.

    *   **`networks`:** (Optional) This section defines *custom networks* that your application's services can be attached to.  This allows for better isolation between different applications or components.

## Compose Main Commands

The `docker-compose` command-line tool provides several useful commands:

*   **`docker-compose up`**:  The most important command.  It does the following:
    *   Builds images (if necessary, based on the `build` directives in your `docker-compose.yml`).
    *   Creates and starts all the containers defined in the `services` section.
    *   Creates any networks and volumes defined in the file.
    *   Connects containers to the appropriate networks.
    *   By default, it runs in the foreground, displaying logs from all containers.
    *   Use `docker-compose up -d` to run in detached mode (background).

*   **`docker-compose down`**:  Stops and *removes* all the containers, networks, and volumes defined in the `docker-compose.yml` file.  This is important to clean up resources.

*   **`docker-compose ps`**:  Shows the current status of all the services (containers) defined in the Compose file (running, stopped, etc.).

*   **`docker-compose logs`**:  Displays the logs for all the containers or a specific service (e.g., `docker-compose logs web`).

*   **`docker-compose exec <service_name> <command>`**:  Allows you to run a specific command *inside* a running container (e.g., `docker-compose exec web bash` to get a shell in the 'web' service container).  This is very useful for debugging.
*   **`docker-compose build`**: Builds (or rebuilds) services. Use this if you've changed your `Dockerfile` or application code.
* **`docker-compose stop`**: Stops running containers without removing them.
* **`docker-compose start`**: Starts existing containers.

## Compose Process

The general workflow for using Docker Compose involves three main steps:

1.  **Define your app's environment with a `Dockerfile` for *each* service that needs a custom image.** This ensures that the container images can be reproduced anywhere.  If you're using pre-built images from Docker Hub, you can skip this step for those services.
2.  **Define the services that make up your app in a `docker-compose.yml` file.** This specifies how they should run together in an isolated environment, including their dependencies, networking, and volumes.
3.  **Run the command `docker-compose up`**. Docker Compose will handle building images (if necessary), creating containers, networks, and volumes, and starting everything up.

## Develop a System using Compose (Example: Webpage Hit Counter)

This example demonstrates how to develop a simple web application with a hit counter using Docker Compose.

*   **Components:**
    *   A simple webpage (served by a Python Flask application).
    *   An application to count the visits (also part of the Flask application).
    *   A caching mechanism to store the count (using Redis).

*   **Technologies:**
    *   Python Flask (for the web application and counter).
    *   Redis (as the in-memory data store for caching the hit count).

### Getting the Files Ready

You need to create three files in a project directory (e.g., `composetest`):

1.  **Python Script (`app.py`) and Requirements File (`requirements.txt`):**

    *   `app.py`: Contains the Flask application code.  It connects to Redis to increment and retrieve the hit count.

        ```python
        # app.py
        from flask import Flask
        from redis import Redis, RedisError
        import os
        import socket

        # Connect to Redis
        redis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)

        app = Flask(__name__)

        @app.route("/")
        def hello():
            try:
                visits = redis.incr("counter")
            except RedisError:
                visits = "<i>cannot connect to Redis, counter disabled</i>"

            html = "<h3>Hello {name}!</h3>" \
                   "<b>Hostname:</b> {hostname}<br/>" \
                   "<b>Visits:</b> {visits}"
            return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)

        if __name__ == "__main__":
            app.run(host='0.0.0.0', port=80)
        ```

    *   `requirements.txt`: Lists the Python dependencies (`flask` and `redis`) required for the application. Using a `requirements.txt` file ensures that all necessary dependencies are installed in the Docker container during the build process, making the environment reproducible.

        ```
        # requirements.txt
        flask
        redis
        ```

2.  **Docker File (`Dockerfile`):** This file contains the instructions to build the Docker image for the Python application.

    ```dockerfile
    # Dockerfile
    FROM python:3.7-alpine
    WORKDIR /code
    ENV FLASK_APP=app.py
    ENV FLASK_RUN_HOST=0.0.0.0
    COPY requirements.txt requirements.txt
    RUN pip install -r requirements.txt
    EXPOSE 5000
    COPY . .
    CMD ["flask", "run"]
    ```

    *   `FROM python:3.7-alpine`:  Starts from a base Python image (a small Alpine Linux-based image).
    *   `WORKDIR /code`: Sets the working directory inside the container to `/code`.
    *   `ENV FLASK_APP=app.py`: Sets environment variable to tell Flask where you app is.
    *   `ENV FLASK_RUN_HOST=0.0.0.0`:  Sets environment variable to tell flask to listen on all interfaces.
    *   `COPY requirements.txt requirements.txt`: Copies the `requirements.txt` file into the container.
    *   `RUN pip install -r requirements.txt`: Installs the Python dependencies.
    *   `EXPOSE 5000`:  Informs Docker that the container listens on port 5000 (but doesn't actually publish the port - that's done in the `docker-compose.yml` file).
    *   `COPY . .`: Copies the rest of the application code (including `app.py`) into the container.
    *   `CMD ["flask", "run"]`: Sets the command to run when the container starts (runs the Flask development server).

3.  **Docker Compose File (`docker-compose.yml`):** This file defines the services (containers) for the application.

    ```yaml
    # docker-compose.yml
    version: "3.9"
    services:
      web:
        build: .
        ports:
          - "8000:5000"
        depends_on:
          - redis
      redis:
        image: "redis:alpine"
    ```

    *   `version: "3.9"`: Specifies the Compose file format version.
    *   `services:`: Defines the services.
        *   `web:`: Defines the web application service.
            *   `build: .`: Builds the image using the `Dockerfile` in the current directory.
            *   `ports: - "8000:5000"`: Maps host port 8000 to container port 5000.
            * `depends_on: - redis`: states that the web service depends on the redis service, so redis will start first.
        *   `redis:`: Defines the Redis service.
            *   `image: "redis:alpine"`: Uses a pre-built Redis image from Docker Hub (the Alpine Linux version, which is small).

### Building and Running the App with Compose

1.  **Make sure Docker Compose is installed:** You can check with `docker-compose --version`.  If it's not installed, use `pip3 install docker-compose` (you might need `sudo`).
2.  **Create a project directory** (e.g., `composetest`) and navigate into it (`cd composetest`).
3.  **Create the three files** (`app.py`, `requirements.txt`, `Dockerfile`, and `docker-compose.yml`) with the content provided above.  Save them in the `composetest` directory.
4.  **Build and run the application:** Use the command `docker-compose up`.  Docker Compose will:
    *   Pull the Redis image from Docker Hub (if you don't have it locally).
    *   Build the web application image using the `Dockerfile`.
    *   Create and start both containers (Redis first, then the web application).
    *   Connect the containers to a default network so they can communicate.

### Testing and Shutting Down

1.  **Test the application:** Open a web browser on the host machine and navigate to `http://localhost:8000/`. You should see the "Hello World!" message with an increasing hit count on each refresh.
2.  You can **check the running containers** using `docker ps` or `docker-compose ps`.
3.  To **stop and remove the application's containers, networks, and volumes**, use the command `docker-compose down`.  This is *very important* to clean up resources.

### Updating the System (Development Mode)

*   **Problem:**  If you modify `app.py`, you need to rebuild the `web` image and restart the container for the changes to take effect (`docker-compose up --build`). This is slow for development.
*   **Solution:** Use a **bind mount** to enable on-the-fly code modification *without* rebuilding the image.  A bind mount allows a file or directory on the *host machine* to be mounted *into* a container.  Changes on the host are immediately reflected in the container, and vice-versa.

*   Modify the `docker-compose.yml` file to include a `volumes` section for the `web` service *and* set the `FLASK_ENV` environment variable to `development`:

```yaml
# docker-compose.yml (updated for development)
version: "3.9"
services:
  web:
    build: .
    ports:
      - "8000:5000"
    volumes:
      - .:/code  # Mount the current directory on the host to /code in the container
    environment:
      FLASK_ENV: development # Tell Flask to run in development mode
    depends_on:
      - redis
  redis:
    image: "redis:alpine"